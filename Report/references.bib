Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Manning2014,
      abstract = {We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.},
      archivePrefix = {arXiv},
      arxivId = {arXiv:1011.1669v3},
      author = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
      doi = {10.3115/v1/P14-5010},
      eprint = {arXiv:1011.1669v3},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/Stanford NLP toolkit.pdf:pdf},
      isbn = {9781941643006},
      issn = {1098-6596},
      journal = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
      pages = {55--60},
      pmid = {25246403},
      title = {{The Stanford CoreNLP Natural Language Processing Toolkit}},
      url = {http://aclweb.org/anthology/P14-5010},
      year = {2014}
}
@article{Bhagwat2018,
      author = {Bhagwat, Vyas Ajay},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/Deep Learning for Chatbots.pdf:pdf},
      journal = {Master's Projects},
      title = {{Deep Learning for Chatbots}},
      url = {http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/},
      year = {2018}
}
@article{Hill2015,
      abstract = {This study analyzed how communication changes when people communicate with an intelligent agent as opposed to with another human. We compared 100 instant messaging conversations to 100 exchanges with the popular chatbot Cleverbot along seven dimensions: words per message, words per conversation, messages per conversation, word uniqueness, and use of profanity, shorthand, and emoticons. A MANOVA indicated that people communicated with the chatbot for longer durations (but with shorter messages) than they did with another human. Additionally, human-chatbot communication lacked much of the richness of vocabulary found in conversations among people, and exhibited greater profanity. These results suggest that while human language skills transfer easily to human-chatbot communication, there are notable differences in the content and quality of such conversations.},
      author = {Hill, Jennifer and {Randolph Ford}, W. and Farreras, Ingrid G.},
      doi = {10.1016/j.chb.2015.02.026},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/hill2015.pdf:pdf},
      issn = {07475632},
      journal = {Computers in Human Behavior},
      keywords = {CMC,Chatbot,Cleverbot,IM,Instant messaging},
      pages = {245--250},
      publisher = {Elsevier Ltd},
      title = {{Real conversations with artificial intelligence: A comparison between human-human online conversations and human-chatbot conversations}},
      url = {http://dx.doi.org/10.1016/j.chb.2015.02.026},
      volume = {49},
      year = {2015}
}
@article{Socher2017,
      abstract = {Keyphrases: Natural Language Processing. Word Vectors. Singu-lar Value Decomposition. Skip-gram. Continuous Bag of Words (CBOW). Negative Sampling. Hierarchical Softmax. Word2Vec. This set of notes begins by introducing the concept of Natural Language Processing (NLP) and the problems NLP faces today. We then move forward to discuss the concept of representing words as numeric vectors. Lastly, we discuss popular approaches to designing word vectors.},
      author = {Socher, Richard and Genthial, Guillaume and Socher, Richard},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/NLP with Deep Learning notes.pdf:pdf},
      keywords = {search},
      pages = {1--14},
      title = {{CS 224 n : Natural Language Processing with Deep Lecture Notes : Part I}},
      year = {2017}
}
@article{Martinez2010,
      abstract = {Approximately 40 years ago, the goal of endowing computers with the capacity to understand natural language began. These efforts were originally called natural language understanding, which is now more frequently called natural language processing (NLP). NLP is considered a branch of artificial intelligence (AI), but over the years it has become an interesting area of study in computational statistics and text data mining. NLP encompasses approaches that use computers to analyze, determine semantic similarity, and translate between languages. The area usually deals with written languages, but it could also be applied to speech. In this article, we cover definitions and concepts necessary for the understanding of NLP, methods at the word and sentence level (word sense disambiguation, part-of-speech tagging, and parsing), and the vector space model for NLP at the document level. Copyright {\textcopyright} 2010 John Wiley {\&} Sons, Inc.For further resources related to this article, please visit the WIREs website.},
      author = {Martinez, Angel R.},
      doi = {10.1002/wics.76},
      file = {:C$\backslash$:/Users/Svetlozar Georgiev/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinez - 2010 - Natural language processing.pdf:pdf},
      issn = {19395108},
      journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
      keywords = {disambiguation,information retrieval,latent semantic indexing,parsing,probabilistic grammars,word sense},
      number = {3},
      pages = {352--357},
      title = {{Natural language processing}},
      volume = {2},
      year = {2010}
}
@article{Yan2016,
      abstract = {Chatbots are emerging as the newest platform used by millions of consumers worldwide due in part to the commoditization of natural language services, which provide provide developers with many building blocks to create chatbots inexpensively. However, it is still difficult to build and deploy chatbots. Developers need to handle the coordination of the cognitive services to build the chatbot interface, integrate the chatbot with external services, and worry about extensibility, scalability, and maintenance. In this work, we present the architecture and prototype of a chatbot using a serverless platform, where developers compose stateless functions together to perform useful actions. We describe our serverless architecture based on function sequences, and how we used these functions to coordinate the cognitive microservices in the Watson Developer Cloud to allow the chatbot to interact with external services. The serverless model improves the extensibility of our chatbot, which currently supports 6 abilities: location based weather reports, jokes, date, reminders, and a simple music tutor.},
      author = {Yan, Mengting and Castro, Paul and Cheng, Perry and Ishakian, Vatche},
      doi = {10.1145/3007203.3007217},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/serverless chatbot.pdf:pdf},
      isbn = {9781450346696},
      journal = {Proceedings of the 1st International Workshop on Mashups of Things and APIs - MOTA '16},
      keywords = {bots,cloud computing,faas,serverless},
      pages = {1--4},
      title = {{Building a Chatbot with Serverless Computing}},
      url = {http://dl.acm.org/citation.cfm?doid=3007203.3007217},
      year = {2016}
}
@article{Mikkonen2018,
      author = {Mikkonen, Tommi},
      doi = {10.1007/978-3-319-74433-9},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/lehv2018.pdf:pdf},
      isbn = {978-3-319-74432-2},
      keywords = {aws,aws lambda,chatbot,facebook messenger,internet bot,microservices,serverless computing},
      pages = {75--86},
      title = {{Current Trends in Web Engineering}},
      url = {http://link.springer.com/10.1007/978-3-319-74433-9},
      volume = {10544},
      year = {2018}
}
@article{Young2017,
      abstract = {Deep learning methods employ multiple processing layers to learn hierarchical representations of data and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.},
      archivePrefix = {arXiv},
      arxivId = {1708.02709},
      author = {Young, Tom and Hazarika, Devamanyu and Poria, Soujanya and Cambria, Erik},
      doi = {arXiv:1708.02709v6},
      eprint = {1708.02709},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/young2018.pdf:pdf},
      issn = {1556-603X VO  - 13},
      journal = {IEEE Computational Intelligence Magazine},
      keywords = {ek laboratories,nanyang technological university},
      number = {July},
      pages = {55--75},
      publisher = {IEEE},
      title = {{Recent Trends in Deep Learning Based Natural Language Processing}},
      url = {http://arxiv.org/abs/1708.02709},
      volume = {13},
      year = {2017}
}
@article{Jia2009,
      abstract = {CSIEC (Computer Simulation in Educational Communication) system with newly developed multiple functions for English instruction still focuses on supplying a virtual chatting partner (chatbot), which can chat in English with the English learners anytime anywhere. It generates communicative response according to the user input, the dialogue context, the user's and its own personality knowledge, common sense knowledge, and inference knowledge. All these kinds of knowledge are expressed in the form of NLML, an annotation language for natural language text. These NLMLs can either be automatically obtained through parsing the text, or be easily authored with the help of GUI editors designed by us. So the CSIEC system suggests a na{\"{i}}ve approach of logical reasoning and inference directly through syntactical and semantic analysis of textual knowledge. This approach has advantages over the old ELIZA-like keywords matching mechanism. The chatting log summarization of free Internet usage within six months demonstrates this advantage. In this paper, we present the system architecture and underlying technologies, and the educational application results. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
      author = {Jia, Jiyou},
      doi = {10.1016/j.knosys.2008.09.001},
      file = {:C$\backslash$:/Users/Svetlozar Georgiev/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia - 2009 - CSIEC A computer assisted English learning chatbot based on textual knowledge and reasoning.pdf:pdf},
      isbn = {0950-7051},
      issn = {09507051},
      journal = {Knowledge-Based Systems},
      keywords = {Chatbot,Computer assisted language learning,Human-computer interaction,Inference,Natural language processing},
      number = {4},
      pages = {249--255},
      publisher = {Elsevier B.V.},
      title = {{CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning}},
      url = {http://dx.doi.org/10.1016/j.knosys.2008.09.001},
      volume = {22},
      year = {2009}
}
@article{Goldberg2015,
      abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in elds such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
      archivePrefix = {arXiv},
      arxivId = {arXiv:1510.00726v1},
      author = {Goldberg, Yoav},
      doi = {10.1613/jair.4992},
      eprint = {arXiv:1510.00726v1},
      file = {:C$\backslash$:/Users/Svetlozar Georgiev/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldberg - 2015 - A Primer on Neural Network Models for Natural Language Processing.pdf:pdf},
      issn = {1076-9757},
      journal = {Report},
      keywords = {Deep Learning,Neural Network},
      pages = {1--75},
      title = {{A Primer on Neural Network Models for Natural Language Processing}},
      volume = {57},
      year = {2015}
}
@article{Pereira2018,
      abstract = {{\textcopyright} 2018 ACM. This work introduces a set of quality attributes for chatbots. The selection is grounded on scholarly but also reputed blog references from 2016 and 2017. In addition, attributes should be amenable to be extracted (semi) automatically. On these premises, we consider four attributes: "support of a minimal set of common commands", "foresee language variations in both inputs and ouput", "human-assistance provision" and "timeliness". These attributes are worked out for the 100 most popular chatbots in Facebook Messager. The aim is to look for correlations between these attributes and chatbot popularity in terms of number of "likes". Results show that there is no significance correlation with any of the attributes. However, the experiment come up with two main insights. First, the lack of common communication paterns that would permit users to move their experiences and expectations from one chatbot to another. Second, the existence of many programming errors that reflect that bot programming is still a nascent area.},
      author = {Pereira, J. and D{\'{i}}az, O.},
      doi = {10.1145/3167132.3167362},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/pereira2018.pdf:pdf},
      isbn = {9781450351911},
      journal = {Proceedings of the ACM Symposium on Applied Computing},
      pages = {2144--2150},
      title = {{A quality analysis of facebook messenger's most popular chatbots}},
      volume = {Part F1378},
      year = {2018}
}
@article{Khatua2017,
      abstract = {{\textcopyright} 2017 IEEE. Data scientists are exploring various semi-supervised learning methods to build conversational agents - commonly known as chatterbot. This paper investigates various issues related to a political chatterbot where human agents are politically opinionated. Here, understanding the latent intent of human agent is crucial for developing an efficient political chatterbot. We set our study in the context of 2016 Brexit referendum. We argue that employing a subjectivity detector and an emotion analyzer, in addition to the keyword based topic detector, enhances the intent detection process. Next, we discuss the importance of maintaining political neutrality. To maintain its neutrality, a chatterbot needs to disassociate itself from a politically opinionated response. This can be achieved by associating a response with a user or a set of users. Nowadays, the Twitter platform provides an enormous amount of user-generated contents for various socio-economic events. Hence, we have considered tweet feeds for developing the overall chatterbot architecture in the political domain.},
      author = {Khatua, Aparup and Cambria, Erik and Khatua, Apalak and Chaturvedi, Iti},
      doi = {10.1109/ICDMW.2017.57},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/08215689.pdf:pdf},
      isbn = {9781538614808},
      issn = {23759259},
      journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
      keywords = {2016 Brexit Referendum,Chatterbot,Twitter},
      pages = {393--398},
      title = {{Let's Chat about Brexit! A Politically-Sensitive Dialog System Based on Twitter Data}},
      volume = {2017-Novem},
      year = {2017}
}
@article{Gardner2017,
      abstract = {This paper describes AllenNLP, a platform for research on deep learning methods in natural language understanding. AllenNLP is designed to support researchers who want to build novel language understanding models quickly and easily. It is built on top of PyTorch, allowing for dynamic computation graphs, and provides (1) a flexible data API that handles intelligent batching and padding, (2) high-level abstractions for common operations in working with text, and (3) a modular and extensible experiment framework that makes doing good science easy. It also includes reference implementations of high quality approaches for both core semantic problems (e.g. semantic role labeling (Palmer et al., 2005)) and language understanding applications (e.g. machine comprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source effort maintained by engineers and researchers at the Allen Institute for Artificial Intelligence.},
      archivePrefix = {arXiv},
      arxivId = {1803.07640},
      author = {Gardner, Matt and Grus, Joel and Neumann, Mark and Tafjord, Oyvind and Dasigi, Pradeep and Liu, Nelson and Peters, Matthew and Schmitz, Michael and Zettlemoyer, Luke},
      eprint = {1803.07640},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/AlienNLP.pdf:pdf},
      pages = {3--8},
      title = {{AllenNLP: A Deep Semantic Natural Language Processing Platform}},
      url = {http://arxiv.org/abs/1803.07640},
      year = {2018}
}
@article{Shawar2005,
      abstract = {{\textless}p{\textgreater}A chatbot is a machine conversation system which interacts with human users via natural conversational language. Software to machine-learn conversational patterns from a transcribed dialogue corpus has been used to generate a range of chatbots speaking various languages and sublanguages including varieties of English, as well as French, Arabic and Afrikaans. This paper presents a program to learn from spoken transcripts of the Dialogue Diversity Corpus of English, the Minnesota French Corpus, the Corpus of Spoken Afrikaans, the Qur'an Arabic-English parallel corpus, and the British National Corpus of English; we discuss the problems which arose during learning and testing. Two main goals were achieved from the automation process. One was the ability to generate different versions of the chatbot in different languages, bringing chatbot technology to languages with few if any NLP resources: the corpus-based learning techniques transferred straightforwardly to develop chatbots for Afrikaans and Qur'anic Arabic. The second achievement was the ability to learn a very large number of categories within a short time, saving effort and errors in doing such work manually: we generated more than one million AIML categories or conversation-rules from the BNC corpus, 20 times the size of existing AIML rule-sets, and probably the biggest AI Knowledge-Base ever.{\textless}/p{\textgreater}},
      author = {Shawar, Bayan Abu and Atwell, Eric Steven},
      doi = {10.1075/ijcl.10.4.06sha},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/shawar2005.pdf:pdf},
      isbn = {00390526},
      issn = {1384-6655},
      journal = {International Journal of Corpus Linguistics},
      keywords = {afrikaans,aiml,an,arabic,artificial intelligence,british national corpus,chatbot,chatbot, dialogue, AIML, Artificial Intelligence,,dialogue,french,learning,lemmatised and unlemmatised lists,machine,qur},
      number = {4},
      pages = {489--516},
      pmid = {10501650},
      title = {{Using corpora in machine-learning chatbot systems}},
      url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.10.4.06sha},
      volume = {10},
      year = {2005}
}
@book{Poole:1997:CIL:275594,
      author = {Poole, David and Mackworth, Alan and Goebel, Randy},
      title = {Computational Intelligence: A Logical Approach},
      year = {1997},
      isbn = {0-19-510270-3},
      publisher = {Oxford University Press, Inc.},
      address = {New York, NY, USA},
} 
@book{RusselStuart,
      archivePrefix = {arXiv},
      arxivId = {arXiv:gr-qc/9809069v1},
      author = {{Russel, Stuart} and {Norvig, Peter}},
      doi = {10.1017/S0269888900007724},
      eprint = {9809069v1},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/a154ffbcec538a4161a406abf62f5b76-original.pdf:pdf},
      isbn = {9780136042594},
      issn = {0269-8889},
      pmid = {20949757},
      primaryClass = {arXiv:gr-qc},
      title = {{Artificial Intelligence 3rd edition}},
      year = {2003},
}
@inproceedings{williams1983brief,
      title={A Brief Introduction to Artificial Intelligence},
      author={Williams, Chuck},
      booktitle={OCEANS'83, Proceedings},
      pages={94--99},
      year={1983},
      organization={IEEE}
}
@article{Khurana2017,
      abstract = {Natural language processing (NLP) has recently gained much attention for representing and analysing human language computationally. It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc. The paper distinguishes four phases by discussing different levels of NLP and components of Natural Language Generation (NLG) followed by presenting the history and evolution of NLP, state of the art presenting the various applications of NLP and current trends and challenges.},
      archivePrefix = {arXiv},
      arxivId = {1708.05148},
      author = {Khurana, Diksha and Koli, Aditya and Khatter, Kiran and Singh, Sukhdev},
      eprint = {1708.05148},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/1708.05148.pdf:pdf},
      number = {Figure 1},
      title = {{Natural Language Processing: State of The Art, Current Trends and Challenges}},
      url = {http://arxiv.org/abs/1708.05148},
      year = {2017}
}
@article{Turing1950,
      author = {Turing, A. M.},
      title = {Computing machinery and intelligence},
      journal = {Mind},
      volume = {LIX},
      number = {236},
      pages = {433-460},
      year = {1950},
      doi = {10.1093/mind/LIX.236.433},
      URL = {http://dx.doi.org/10.1093/mind/LIX.236.433},
      eprint = {/oup/backfile/content_public/journal/mind/lix/236/10.1093_mind_lix.236.433/1/433.pdf}
}
@article{Lecun2015,
      abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
      archivePrefix = {arXiv},
      arxivId = {arXiv:1312.6184v5},
      author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
      doi = {10.1038/nature14539},
      eprint = {arXiv:1312.6184v5},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/NatureDeepReview.pdf:pdf},
      isbn = {9780521835688},
      issn = {14764687},
      journal = {Nature},
      number = {7553},
      pages = {436--444},
      pmid = {10463930},
      title = {{Deep learning}},
      volume = {521},
      year = {2015}
}
@book{Kononenko2007,
      abstract = {Deep learning is a specific kind of machine learning. In order to understand deep learning well, one must have a solid understanding of the basic principles of ma-chine learning. This chapter provides a brief course in the most important general principles that will be applied throughout the rest of the book. Novice readers or those that want a wider perspective are encouraged to consider machine learning textbooks with a more comprehensive coverage of the fundamentals, such as Mur-phy (2012) or Bishop (2006). If you are already familiar with machine learning basics, feel free to skip ahead to Section 5.12. That section covers some perspec-tives on traditional machine learning techniques that have strongly influenced the development of deep learning algorithms. 5.1 Learning Algorithms A machine learning algorithm is an algorithm that is able to learn from data. But what do we mean by learning? A popular definition of learning in the context of computer programs is " A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experience E " (Mitchell, 1997). One can imagine a very wide variety of experiences E, tasks T , and performance measures P , and we do not make any attempt in this book to provide a formal definition of what may be used for each of these entities. Instead, the following sections provide intuitive descriptions and examples of the different kinds of tasks, performance measures and experiences that can be used to construct machine learning algorithms. 92},
      archivePrefix = {arXiv},
      arxivId = {0905.2485},
      author = {Kononenko, Igor and Kukar, Matja{\v{z}}},
      booktitle = {Machine Learning and Data Mining},
      doi = {10.1533/9780857099440.59},
      eprint = {0905.2485},
      file = {:D$\backslash$:/OneDrive - Edinburgh Napier University/Hons Project/Papers/sarkar2018.pdf:pdf},
      isbn = {978-1-90427-521-3},
      issn = {1422-6405},
      pages = {59--105},
      pmid = {17476286},
      title = {{Machine Learning Basics}},
      url = {http://linkinghub.elsevier.com/retrieve/pii/B9781904275213500034},
      year = {2007}
}



